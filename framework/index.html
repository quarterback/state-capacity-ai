<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ACX Framework — State Capacity AI</title>
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1><a href="/">State Capacity AI</a></h1>
            <nav>
                <a href="/framework">Framework</a>
                <a href="/experiments">Experiments</a>
                <a href="https://blog.ronbronson.com">Blog</a>
            </nav>
        </div>
    </header>

    <main>
        <section class="content">
            <div class="container">
                <h2>Agent-Context Experience (ACX)</h2>
                
                <p class="lead">Agent Experience (AX) teaches us to design for agents as users. Agent-Context Experience (ACX) teaches us to design the contexts those agents operate within.</p>

                <h3>Five Design Principles</h3>

                <article class="principle">
                    <h4>1. Context as Environment, Not Just Input</h4>
                    <p>Where is this system being deployed? What assumptions does it carry? What power does it hold? Context isn't just what's in the window—it's the environment the system enters.</p>
                </article>

                <article class="principle">
                    <h4>2. Disintermediation Analysis</h4>
                    <p>When does AI mediation separate people from relationships, capabilities, and decision-making? Not just "is the agent working?" but "is mediation helping or hurting?"</p>
                </article>

                <article class="principle">
                    <h4>3. System Accountability</h4>
                    <p>Who has to live with the outcome when the system gets it wrong? Not just "did the agent complete the task?" but "was the outcome right for the person?"</p>
                </article>

                <article class="principle">
                    <h4>4. Escalation & Refusal Design</h4>
                    <p>How do systems recognize their limits and know when to stop? Not just "can the agent handle edge cases?" but "can it admit when it can't?"</p>
                </article>

                <article class="principle">
                    <h4>5. Capability Preservation</h4>
                    <p>How do we ensure AI enhances rather than erodes human capability? Not just "is the interface intuitive?" but "are people learning or losing skills?"</p>
                </article>

                <hr>

                <h3>Background</h3>
                <p>This framework builds on years of work in <a href="https://blog.ronbronson.com/service-design-for-ai-why-human-experience-hx-matters">consequence design</a> and service design. It extends Agent Experience (AX) principles for deployment contexts where failure has real consequences: government services, healthcare, customer support, HR.</p>

                <p><strong>Read more:</strong></p>
                <ul>
                    <li><a href="https://blog.ronbronson.com/context-is-about-more-than-prompts/">Context is about more than prompts</a></li>
                    <li><a href="https://blog.ronbronson.com/context-engineering-for-llms-starts-with-systems-not-prompts/">Context Engineering for LLMs Starts With Systems, Not Prompts</a></li>
                </ul>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>By <a href="https://blog.ronbronson.com">Ron Bronson</a></p>
        </div>
    </footer>
</body>
</html>
