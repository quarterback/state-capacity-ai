<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>State Capacity AI - Context Engineering for Public Deployment</title>
    <meta name="description" content="A public R&D lab exploring context engineering, agent experience, and AI deployment in high-stakes environments.">
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1><a href="/">State Capacity AI</a></h1>
            <nav>
                <a href="/framework">Framework</a>
                <a href="/experiments">Experiments</a>
                <a href="https://blog.ronbronson.com">Writing</a>
            </nav>
        </div>
    </header>

    <main>
        <section class="hero">
            <div class="container">
                <h2>Context Engineering Starts With Systems, Not Prompts</h2>
                <p class="lead">A public R&D lab exploring how AI systems work in contexts where failure has consequences. Building working prototypes, not just writing about them.</p>
            </div>
        </section>

        <section class="problem">
            <div class="container">
                <h3>The Problem</h3>
                <p>We're letting an ICQ window dictate the course of the next few years. Agents are being deployed in government services, healthcare, customer support—places where people don't have alternatives and "try again" isn't an option.</p>
                <p>When systems fail, people don't get a second chance. They absorb the error, explain what went wrong, or try to fix something they didn't break.</p>
                <p><strong>That's the new context burden. And it's going to land hardest on people who are already carrying too much.</strong></p>
            </div>
        </section>

        <section class="approach">
            <div class="container">
                <h3>What This Is</h3>
                <p>State Capacity AI is a public research lab for exploring context engineering in high-stakes deployment environments.</p>
                
                <div class="grid">
                    <div class="card">
                        <h4>Agent-Context Experience (ACX)</h4>
                        <p>A framework for designing AI systems that know what they are, recognize their limits, and stay accountable to the people using them.</p>
                        <a href="/framework" class="button">Explore Framework →</a>
                    </div>
                    
                    <div class="card">
                        <h4>Working Experiments</h4>
                        <p>Not mockups or whitepapers. Actual prototypes that demonstrate design principles for context legibility, escalation patterns, and capability preservation.</p>
                        <a href="/experiments" class="button">See Experiments →</a>
                    </div>
                    
                    <div class="card">
                        <h4>Deployment Analysis</h4>
                        <p>Case studies examining where AI mediation creates problems in real contexts—and what to do about it.</p>
                        <a href="https://blog.ronbronson.com/context-is-about-more-than-prompts/" class="button">Latest Writing →</a>
                    </div>
                </div>
            </div>
        </section>

        <section class="current">
            <div class="container">
                <h3>Current Work</h3>
                <p class="note">Building in public. New experiments shipping weekly.</p>
                
                <div class="experiment-list">
                    <article class="experiment">
                        <span class="exp-number">#001</span>
                        <h4>Context Legibility Dashboard</h4>
                        <p>Making system assumptions, limits, and reasoning visible to end users.</p>
                        <span class="status">In Progress</span>
                    </article>
                    
                    <article class="experiment">
                        <span class="exp-number">#002</span>
                        <h4>Escalation Pattern Library</h4>
                        <p>Designing for when systems should refuse, ask for help, or admit uncertainty.</p>
                        <span class="status">Planned</span>
                    </article>
                    
                    <article class="experiment">
                        <span class="exp-number">#003</span>
                        <h4>Disintermediation Case Studies</h4>
                        <p>Documenting where agent mediation creates problems in government and public services.</p>
                        <span class="status">Planned</span>
                    </article>
                </div>
            </div>
        </section>

        <section class="about">
            <div class="container">
                <h3>About This Project</h3>
                <p>State Capacity AI is led by <a href="https://blog.ronbronson.com">Ron Bronson</a>, drawing on years of work in consequence design, service design, and public sector technology.</p>
                <p>This project explores:</p>
                <ul>
                    <li>How AI agents interpret and act on human intent in high-stakes contexts</li>
                    <li>Where system assumptions create risks in public deployment</li>
                    <li>When AI mediation helps versus when it hides problems</li>
                    <li>How to design for escalation, refusal, and uncertainty</li>
                    <li>Ways to preserve human capability in AI-mediated systems</li>
                </ul>
                <p><strong>This isn't about resisting AI deployment. It's about ensuring these systems enhance rather than erode public capacity.</strong></p>
            </div>
        </section>

        <section class="foundation">
            <div class="container">
                <h3>Foundational Writing</h3>
                <ul class="post-list">
                    <li><a href="https://blog.ronbronson.com/context-is-about-more-than-prompts/">Context is about more than prompts</a> <span class="date">October 2025</span></li>
                    <li><a href="https://blog.ronbronson.com/context-engineering-for-llms-starts-with-systems-not-prompts/">Context Engineering for LLMs Starts With Systems, Not Prompts</a> <span class="date">June 2025</span></li>
                    <li><a href="https://blog.ronbronson.com/service-design-for-ai-why-human-experience-hx-matters">Service Design for AI: Why Human Experience (HX) Matters</a> <span class="date">February 2025</span></li>
                </ul>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>State Capacity AI — A public research lab by <a href="https://blog.ronbronson.com">Ron Bronson</a></p>
            <p><a href="https://bsky.app/profile/ronbronson.bsky.social">Bluesky</a> · <a href="https://blog.ronbronson.com/rss.xml">RSS</a></p>
        </div>
    </footer>
</body>
</html>
